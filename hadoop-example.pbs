# !/bin/bash
# Hadoop HPCC Cluster Test Job
#PBS -j eo
#PBS -l walltime=00:30:00
#PBS -l nodes=3:ppn=6
#PBS -l pmem=2g

WORK_HOME=/path/to/work_home

echo $(date) - HADOOP PBS Job Started

source $WORK_HOME/setup.sh

# This starts HDFS and the job and task trackers
$WORK_HOME/launch-up-hadoop-on-hpcc

# Check to make sure hadoop started up before running our code.
if [ $? -eq 0 ]; then
  cd $WORK_HOME

  # start the wordcount job
  hadoop dfs -mkdir -p /user/hduser/wordcount
  hadoop dfs -copyFromLocal pg20417.txt /user/hduser/wordcount/pg20417.txt
  hadoop dfs -ls /user/hduser/wordcount
  hadoop jar /usr/usc/hadoop/1.1.2/hadoop-examples-1.1.2.jar wordcount /user/hduser/wordcount /user/hduser/wordcount-output
  hadoop dfs -cat /user/hduser/wordcount-output/part-r-00000

  # when this script exits the hadoop cluster is shutdown so copy off data here
  hadoop dfs -copyToLocal /user/hduser/wordcount-output/part-r-00000 ./

fi

echo $(date) - HADOOP PBS Job Finished

